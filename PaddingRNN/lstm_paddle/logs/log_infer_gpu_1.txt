nohup: ignoring input
+ export CUDA_VISIBLE_DEVICES=3
+ python train.py --data_path data/simple-examples/data/ --model_type large --use_gpu True --inference_only True --batch_size 1
2019-03-14 10:58:18,635 - lm - INFO - Running with args : Namespace(batch_size=1, data_path='data/simple-examples/data/', enable_ce=False, inference_only=True, init_model=None, log_path=None, model_type='large', profile=False, rnn_model='static', save_model_dir='models', use_gpu=True)
2019-03-14 10:58:18,635 - INFO - Running with args : Namespace(batch_size=1, data_path='data/simple-examples/data/', enable_ce=False, inference_only=True, init_model=None, log_path=None, model_type='large', profile=False, rnn_model='static', save_model_dir='models', use_gpu=True)
W0314 10:58:22.321938  3609 device_context.cc:263] Please NOTE: device: 0, CUDA Capability: 70, Driver API Version: 9.2, Runtime API Version: 9.2
W0314 10:58:22.322000  3609 device_context.cc:271] device: 0, cuDNN Version: 7.0.
memory_optimize is deprecated. Use CompiledProgram and Executor
ParallelExecutor is deprecated. Please use CompiledProgram and Executor. CompiledProgram is a central place for optimization and Executor is the unified executor. Example can be found in compiler.py.
W0314 10:59:12.022914  3609 graph.h:204] WARN: After a series of passes, the current graph can be quite different from OriginProgram. So, please avoid using the `OriginProgram()` method!
begin to load data
vocab word num 10000
finished load data

======== Benchmark Result ========
Eval batch_size: 1; Time (total): 74.87886 s; Time (only run): 74.61076 s; ppl: 10016.40043

