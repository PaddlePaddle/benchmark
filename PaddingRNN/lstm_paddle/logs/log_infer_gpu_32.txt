nohup: ignoring input
+ export CUDA_VISIBLE_DEVICES=3
+ python train.py --data_path data/simple-examples/data/ --model_type large --use_gpu True --inference_only True --batch_size 32
2019-03-14 11:05:50,097 - lm - INFO - Running with args : Namespace(batch_size=32, data_path='data/simple-examples/data/', enable_ce=False, inference_only=True, init_model=None, log_path=None, model_type='large', profile=False, rnn_model='static', save_model_dir='models', use_gpu=True)
2019-03-14 11:05:50,097 - INFO - Running with args : Namespace(batch_size=32, data_path='data/simple-examples/data/', enable_ce=False, inference_only=True, init_model=None, log_path=None, model_type='large', profile=False, rnn_model='static', save_model_dir='models', use_gpu=True)
W0314 11:05:54.159832  3760 device_context.cc:263] Please NOTE: device: 0, CUDA Capability: 70, Driver API Version: 9.2, Runtime API Version: 9.2
W0314 11:05:54.159909  3760 device_context.cc:271] device: 0, cuDNN Version: 7.0.
memory_optimize is deprecated. Use CompiledProgram and Executor
ParallelExecutor is deprecated. Please use CompiledProgram and Executor. CompiledProgram is a central place for optimization and Executor is the unified executor. Example can be found in compiler.py.
W0314 11:06:38.196890  3760 graph.h:204] WARN: After a series of passes, the current graph can be quite different from OriginProgram. So, please avoid using the `OriginProgram()` method!
begin to load data
vocab word num 10000
finished load data

======== Benchmark Result ========
Eval batch_size: 32; Time (total): 3.32011 s; Time (only run): 3.29429 s; ppl: 10018.52930

